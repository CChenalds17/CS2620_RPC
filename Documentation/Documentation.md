# Wire Protocols: Documentation
Charlie Chen and Eric Gong

## Contents
- Folder and file layout
- High-level Server Organization
- DataObjects and Custom Serialization


## Folder and File Layout
Directoy names are bolded, file names are italicized. Some less relevant directories and files are ommitted; the ommission is noted in the bullet of the parent directory.
- **Code**: Contains all currently used code
    - **Modules**: Contains Classes and Constants used in *ServerDaemon.py*, *Client.py* and similar python scripts
        - *DataObjects.py*: A DataObject Class for all inter-process communication and MessageObject Class for messages specifically 
        - *DatabaseManager.py*: A DatabaseManager Class that handles all database related actions (querying, inserting, deleting, etc.)
        - *Constants.py*: A configuration file containing the constants that are used by the DataObjects and DatabaseManager classes
        - *Flags.py*: A definition of the possible Requests and Statuses for the DataObject Class
        - *SelectorData.py*: A SelectorData Class used by the selectors in ServerDaemon.py
    - **User_Data**: Contains the Password.db and Message.db databases (.db files are ommitted)
    - **Tests**: Contains tests for the Database and DataObjects (DataObject and MessageObject) (test files are ommitted)
    - **Analytics**: Contains plots, test data, and results used in, or generated by *Analytics.py* (test data and results files ommitted)
        - **Plots**: Contains the plots generated by *Analytics.py*
    - *Client.py*: Code to run the client-side of the project
    - *ServerDaemon.py*: Code to run the server-side of the project
    - *TerminalClient.py*: Simple terminal-based client end, useful for debugging
    - *Analytics.py*: Used to quantify the difference between Custom and Json Wire Protocols
- **Documentation**: Contains the Engineering Notebook, notes on Code Review Groups, and this documentation document
    - *Documentation.md*
    - *engineering_notebook.md*
    - *Group_notes.md*
- **Old_Versions**: Used as a repository for older versions of the client and server code (subdirectories and files ommitted)
- **venv**: Virtual Python Environment (subdirectories and files ommitted)

## High-level Server Organization
Our server involves three main components: a single Daemon process, a single Database process, Login processes, and User processes. 

On the Server side:
Upon starting up, the Daemon process first creates a Database process, to handle all databse queries from Login processes and User processes. The Daemon process handles incoming Client connections, spawning (not forking) a new Login process for each connection. Should the Client succeed in the login, the Login process spawns a new User process to handle normal operations.

On the Client side:
The Client code is a script which runs a single Client process that initiates one connection with the Daemon process. The Client process is oblivious and agnostic (in terms of functionality) to the transition between various processes (Daemon, Login, User) on the Server side.

We choose this framework for three main reasons: Scalability, Simplicity, and Security.

# Scalability
As opposed to having a single process handle incomming connections, Client requests, and Database queries, we choose to spawn multiple processes to handle these tasks. This supports scalability as it allows for the batching of tasks. For instance, imagine the process of querying messages: if a Client requests 10 messages, the User process (on the Server side) could request 100 from the database (or even, the User process could pre-laod 100 messages upon Client login), and provide 10 to the Client. Should the Client request 10 more messages or 20 more, no additional database queries are needed. In addition, simple tasks, such as ensuring the validity of requests can be conducted in a User process running concurrently to other user processes. If all Server-side tasks were handled one-at-a time by a single process, the Server would suffer if more clients attempted to connect. While it is true that no server can support arbitrarily large number of processes, additional cores and additional memory to host more processes is far more cost-effective than attempting to hyper-optimize single-threaded code to support more users.

# Simplicity
One may wonder about the choice to have exactly a single Database process. Indeed, our server has only one process handle all database queries. We do this for simplicity: with a single Database process, we need not worry about implementing locks to prevent race conditions and concurrent writes. We note however, that a signle Database process is sufficient for the purposes of a messaging platform: the majority of the user's time will be spent reading messages, drafting messages, and being idle; as such for any given user, the queries generated to the database will be in bursts and fairly infrequent. In combination with techniques such as batching - made possible by dedicated user processes - it is viable to have a single dedicated Database process.

# Security
There are a plethora of security benefits to having dedicated processes. To name a few:
- It is possible to restrict the permissions of a User process (ie: file system restrictions via *chroot*), such that even if Client is malicious and intelligent, capable of subverting a server-side process, the damages can be mitigates. Having the ability to directly communicate with the server increases the risk of subverting a process with high enough priviledge and file access permission to do damage
- It is possible to mitigate the damage of potential implementation bugs. Imagine that an error in the de-serialization process caused the process to crash. In a single process server, the entire server would come to a halt. In the case of a multi-process system, only a single User Process would crash, limiting the impact of damages.
- It is possible to efficiently implement complex authentication and encryption techniques with minimal negative impacts on scalability. The Diffie-Hellman Protocol, a standard method for negotiating a symmetric key for secure communications, requires a non-trivial amount of time. Should it be conducted with a single server process that directly handles all clients, the negative impacts on scalability would be noticable, and more complex cryptographic techniques would only result in more negative impacts.


# Notes and Considerations
- On the matter of the benefits of this framework, while it is true that we have not had the time to implement many of the mentioned strategies for fully levveraging a multi-process server, by creating this foundation, we make such strategies possible, which ultimately ensures scalability over systems for which these strategies cannot be implemented, due to an insufficient foundation.
- On the matter of creating new processes, we use the *multiprocessing* library to handle the creation (via spawning) of the Database process, Login processes, and User processes. Due to cross-system compatibility with POSIX systems, we cannot use os.fork from the *os* library, nor can we use the fork method provided by *multiprocessing*. However, spawning is also convenient as it creates a completely new python environment, maintaining no state from the parent. This makes it easier to safely use global variables that would otherwise be a potential source for race conditions.
- On the matter of batching requests, we note that it would be unwise to attempt to batch on the client end. In the case of getting messages, for example, there are no gurantees on the network speed or memory capacity of the user's device. It would be unwise to send 100 messages at once to the client, and far better instead, to store them on a dedicated Client process.
- On the matter of a singular Database Process, we note that crude (low granularity) locking mechanisms that are not well engineered provide no gurantees of performance over having a single database process, given that crude locking mechanisms essentially limit the writing of the files to one-process-at-a-time. Yet the finer grain the scheme, the more locks that are implemented, the more likely implementations may be imperfect and contain bugs.

## DataObjects and Custom Serialization
We create a universal DataObject to standardize the interface by which the Client and Server communicate, as well as the interface by which the various server-side processes inter-communicate. We also create a MessageObject to store the contents of a single message. Multiple MessageObjects can be placed within a single DataObject.

# DataObject
We support the following fields in the DataObject:
- Request (Of type Request) to specify the specific request that is being issued or responded to
- Status (Of type Status) to specify the status of the returned request (Initially Status.PENDING when issued)
- Sequence (Of type int) to specify a unique identifier for each DataObject (inspired by IP Sequence numbers)
- User (Of type str) to specify the Client username issuing the request (blank before login confirmed)
- Datalen (Of type int) to specify the number of elements in Data (as a sanity check of data validity)
- Data (Of type list[str]) to specify the data being passed within the DataObject (such as a serialized MessageObject)

# MessageObject
We support the following fields in the MessageObject:
- Id (Of type int) to specify a unique identifier for each message (generated by the database, 0 before assignment)
- Sender (Of type str) to specify the sender
- Recipient (Of type str) to specify the recipient
- Time_sent (Of type str) to specify the time the message was sent
- Read (Of type bool) to specify whether the message has been read (delivered)
- Subject (Of type str) to specify the subject
- Body (Of type str) to specify the body of the messsage

# Custom Serialization:
For the Custom serialization, we hoped to design a serialization method that is highly efficient, containing minimal overhead, and thus being close to the same size as the data to be sent. To do this, we choose to separate each of the fields via "\n". To ensure that the fields themselves do not contain "\n", we define an encoder that maps "\n" to "%0". To ensure that the fields themselves do not contain "%0" naturally, we map all "%" to "%0". Thus, this creates a bijective mapping between any arbitrary field (which may need to be re-represented as a string, such as the case of the Request or Status flags) and a version of the field guaranteed not to contain "\n".

After separating fields with "\n", we wish to further ensure that we can ensure the start and end of messages can be easily identified. This is necessary if multiple messages are read out of the socket in a single instance, or if a long message breaks across muliple reads out of the socket. To do this, we serialize the concatenation of the fields, and wrap the concatenation with "\n". If one of the fields is a list, as is the case with DataObject.data, we can encode the list in the same method

A quick toy example:
1. We start with Field1, Field2, List\[Data1, Data2\]
2. We encode the list: Field1, Field2, (Encoded(Data1) + "\n" + Encoded(Data2))
3. We encode the Fields: Encoded(Field1) + "\n" + Encoded(Field2) + "\n" + Encoded((Encoded(Data1) + "\n" + Encoded(Data2)))
4. We encode to yeild the final serialized string: "\n" + Encoded(Encoded(Field1) + "\n" + Encoded(Field2) + "\n" + Encoded((Encoded(Data1) + "\n" + Encoded(Data2)))) + "\n"

Notes:
- Each encoding is a linear scan through the utf-8 byte encoding of each Field or Data item. We currently scan multiple times, but this could be changed to a more advanced single scan. For instance, a double encode changes "\n" to "%01" and a "%" to "%00", so this could be done in one pass instead of 2. 